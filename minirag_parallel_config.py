#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MiniRAGå¹¶è¡Œæ§åˆ¶é…ç½®æ–‡ä»¶
ç”¨äºä¼˜åŒ–extract_entitieså‡½æ•°çš„LLMè°ƒç”¨å¹¶è¡Œæ€§
"""

import os
import asyncio
from typing import Dict, List, Any, Tuple
from collections import defaultdict

# å¹¶è¡Œæ§åˆ¶é…ç½®
PARALLEL_CONFIG = {
    'MAX_CONCURRENT_LLM_CALLS': 8,  # æœ€å¤§å¹¶å‘LLMè°ƒç”¨æ•°
    'BATCH_SIZE': 16,               # æ‰¹å¤„ç†å¤§å°
    'ENABLE_PARALLEL_EXTRACTION': True,  # å¯ç”¨å¹¶è¡Œå®ä½“æå–
    'ENABLE_PARALLEL_RELATIONSHIPS': True,  # å¯ç”¨å¹¶è¡Œå…³ç³»æå–
    'MAX_RETRIES': 3,               # æœ€å¤§é‡è¯•æ¬¡æ•°
    'TIMEOUT_PER_CALL': 30,         # æ¯æ¬¡è°ƒç”¨çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
}

class ParallelEntityExtractor:
    """å¹¶è¡Œå®ä½“æå–å™¨ï¼Œç”¨äºæ›¿æ¢MiniRAGå†…éƒ¨çš„ä¸²è¡Œè°ƒç”¨"""
    
    def __init__(self, llm_func, config=None):
        self.llm_func = llm_func
        self.config = config or PARALLEL_CONFIG
        self.semaphore = asyncio.Semaphore(self.config['MAX_CONCURRENT_LLM_CALLS'])
    
    async def extract_entities_parallel(
        self,
        chunks: Dict[str, Any],
        knowledge_graph_inst,
        entity_vdb,
        entity_name_vdb,
        relationships_vdb,
        global_config: dict
    ):
        """å¹¶è¡Œç‰ˆæœ¬çš„å®ä½“æå–å‡½æ•°"""
        
        if not self.config['ENABLE_PARALLEL_EXTRACTION']:
            # å¦‚æœæœªå¯ç”¨å¹¶è¡Œï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•
            return await self._extract_entities_original(
                chunks, knowledge_graph_inst, entity_vdb, 
                entity_name_vdb, relationships_vdb, global_config
            )
        
        print(f"ğŸš€ å¼€å§‹å¹¶è¡Œå®ä½“æå–ï¼Œæ–‡æœ¬å—æ•°: {len(chunks)}")
        print(f"âš¡ å¹¶è¡Œé…ç½®: æœ€å¤§å¹¶å‘={self.config['MAX_CONCURRENT_LLM_CALLS']}, æ‰¹å¤„ç†å¤§å°={self.config['BATCH_SIZE']}")
        
        # åˆ†æ‰¹å¤„ç†æ–‡æœ¬å—
        ordered_chunks = list(chunks.items())
        all_entities = []
        all_relationships = []
        
        for batch_start in range(0, len(ordered_chunks), self.config['BATCH_SIZE']):
            batch_end = min(batch_start + self.config['BATCH_SIZE'], len(ordered_chunks))
            batch_chunks = dict(ordered_chunks[batch_start:batch_end])
            
            print(f"ğŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_start//self.config['BATCH_SIZE'] + 1}: æ–‡æœ¬å— {batch_start+1}-{batch_end}")
            
            # å¹¶è¡Œå¤„ç†å½“å‰æ‰¹æ¬¡
            batch_entities, batch_relationships = await self._process_batch_parallel(
                batch_chunks, global_config
            )
            
            all_entities.extend(batch_entities)
            all_relationships.extend(batch_relationships)
            
            print(f"âœ… æ‰¹æ¬¡å®Œæˆ: æå–äº† {len(batch_entities)} ä¸ªå®ä½“, {len(batch_relationships)} ä¸ªå…³ç³»")
        
        print(f"ğŸ‰ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼æ€»è®¡: {len(all_entities)} ä¸ªå®ä½“, {len(all_relationships)} ä¸ªå…³ç³»")
        
        # è¿™é‡Œéœ€è¦è°ƒç”¨åŸæœ‰çš„åˆå¹¶å’Œå­˜å‚¨é€»è¾‘
        # ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥ä¿®æ”¹MiniRAGå†…éƒ¨ï¼Œè¿™é‡Œè¿”å›å¤„ç†åçš„æ•°æ®
        return {
            'entities': all_entities,
            'relationships': all_relationships,
            'chunks_processed': len(chunks)
        }
    
    async def _process_batch_parallel(self, batch_chunks: Dict, global_config: dict):
        """å¹¶è¡Œå¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ–‡æœ¬å—"""
        
        # åˆ›å»ºæ‰€æœ‰éœ€è¦çš„æç¤º
        all_prompts = []
        for chunk_key, chunk_data in batch_chunks.items():
            content = chunk_data["content"]
            
            # ç®€åŒ–çš„æç¤ºï¼Œå‡å°‘LLMè°ƒç”¨æ¬¡æ•°
            prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ï¼Œä»¥JSONæ ¼å¼è¿”å›ï¼š

æ–‡æœ¬å†…å®¹ï¼š
{content}

è¯·è¿”å›æ ¼å¼ï¼š
{{
  "entities": [
    {{"name": "å®ä½“å", "type": "å®ä½“ç±»å‹", "description": "æè¿°"}}
  ],
  "relationships": [
    {{"source": "æºå®ä½“", "target": "ç›®æ ‡å®ä½“", "relation": "å…³ç³»ç±»å‹"}}
  ]
}}"""
            
            all_prompts.append((chunk_key, prompt))
        
        # å¹¶è¡Œè°ƒç”¨LLM
        async def single_llm_call(chunk_key, prompt):
            async with self.semaphore:
                try:
                    # è®¾ç½®è¶…æ—¶
                    result = await asyncio.wait_for(
                        self.llm_func(prompt), 
                        timeout=self.config['TIMEOUT_PER_CALL']
                    )
                    return chunk_key, result, None
                except asyncio.TimeoutError:
                    return chunk_key, None, "è°ƒç”¨è¶…æ—¶"
                except Exception as e:
                    return chunk_key, None, str(e)
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰LLMè°ƒç”¨
        tasks = [single_llm_call(chunk_key, prompt) for chunk_key, prompt in all_prompts]
        results = await asyncio.gather(*tasks)
        
        # å¤„ç†ç»“æœ
        batch_entities = []
        batch_relationships = []
        
        for chunk_key, result, error in results:
            if error:
                print(f"âš ï¸ è·³è¿‡å¤±è´¥çš„æ–‡æœ¬å— {chunk_key}: {error}")
                continue
            
            try:
                # è§£æJSONç»“æœ
                import json
                parsed = json.loads(result)
                
                # å¤„ç†å®ä½“
                if "entities" in parsed:
                    for entity in parsed["entities"]:
                        batch_entities.append({
                            "entity_name": entity.get("name", ""),
                            "entity_type": entity.get("type", ""),
                            "description": entity.get("description", ""),
                            "chunk_key": chunk_key
                        })
                
                # å¤„ç†å…³ç³»
                if "relationships" in parsed:
                    for rel in parsed["relationships"]:
                        batch_relationships.append({
                            "src_id": rel.get("source", ""),
                            "tgt_id": rel.get("target", ""),
                            "relation_type": rel.get("relation", ""),
                            "chunk_key": chunk_key
                        })
                
            except Exception as e:
                print(f"âš ï¸ è§£æç»“æœå¤±è´¥ {chunk_key}: {e}")
        
        return batch_entities, batch_relationships
    
    async def _extract_entities_original(self, chunks, knowledge_graph_inst, entity_vdb, 
                                       entity_name_vdb, relationships_vdb, global_config):
        """åŸå§‹çš„å®ä½“æå–æ–¹æ³•ï¼ˆä½œä¸ºfallbackï¼‰"""
        print("âš ï¸ ä½¿ç”¨åŸå§‹å®ä½“æå–æ–¹æ³•")
        # è¿™é‡Œåº”è¯¥è°ƒç”¨åŸå§‹çš„extract_entitieså‡½æ•°
        # ä½†ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥å¯¼å…¥ï¼Œè¿™é‡Œè¿”å›ç©ºç»“æœ
        return {
            'entities': [],
            'relationships': [],
            'chunks_processed': len(chunks)
        }

def create_parallel_extractor(llm_func, config=None):
    """åˆ›å»ºå¹¶è¡Œå®ä½“æå–å™¨å®ä¾‹"""
    return ParallelEntityExtractor(llm_func, config)

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    
    # æ¨¡æ‹ŸLLMå‡½æ•°
    async def mock_llm_func(prompt):
        await asyncio.sleep(1)  # æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
        return '{"entities": [{"name": "æµ‹è¯•å®ä½“", "type": "æ¦‚å¿µ", "description": "æµ‹è¯•æè¿°"}], "relationships": []}'
    
    # åˆ›å»ºå¹¶è¡Œæå–å™¨
    extractor = create_parallel_extractor(
        llm_func=mock_llm_func,
        config=PARALLEL_CONFIG
    )
    
    # æ¨¡æ‹Ÿæ–‡æœ¬å—æ•°æ®
    mock_chunks = {
        f"chunk_{i}": {"content": f"è¿™æ˜¯ç¬¬{i}ä¸ªæ–‡æœ¬å—çš„å†…å®¹"} 
        for i in range(20)
    }
    
    # æ‰§è¡Œå¹¶è¡Œæå–
    result = await extractor.extract_entities_parallel(
        chunks=mock_chunks,
        knowledge_graph_inst=None,
        entity_vdb=None,
        entity_name_vdb=None,
        relationships_vdb=None,
        global_config={}
    )
    
    print(f"æå–ç»“æœ: {result}")

if __name__ == "__main__":
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(example_usage())
