# ========================================
# MiniRAG 服务器配置文件
# ========================================

# ========================================
# 服务器配置
# ========================================
# 服务器主机地址
HOST=localhost
# 服务器端口
PORT=9721

# ========================================
# 目录配置
# ========================================
# RAG存储工作目录
WORKING_DIR=./rag_storage
# 输入文档目录
INPUT_DIR=./dataset/kotei

# ========================================
# LLM配置
# ========================================
# LLM绑定类型 (ollama, lollms, openai)
LLM_BINDING=openai
# LLM服务器主机URL
LLM_BINDING_HOST=https://api.deepseek.com
# LLM服务器API密钥（自动获取DEEPSEEK_API_KEY环境变量）
LLM_BINDING_API_KEY=${DEEPSEEK_API_KEY}
# LLM模型名称
LLM_MODEL=deepseek-chat

# ========================================
# 嵌入配置
# ========================================
# 嵌入绑定类型 (ollama, lollms, openai)
EMBEDDING_BINDING=ollama
# 嵌入服务器主机URL
EMBEDDING_BINDING_HOST=
# 嵌入服务器API密钥
EMBEDDING_BINDING_API_KEY=
# 嵌入模型名称
EMBEDDING_MODEL=mxbai-embed-large:latest
# 嵌入维度
EMBEDDING_DIM=1024
# 最大嵌入token数
MAX_EMBED_TOKENS=8192

# ========================================
# 文本分块配置
# ========================================
# 文本分块大小
CHUNK_SIZE=1200
# 分块重叠大小
CHUNK_OVERLAP_SIZE=100
# Tokenizer模型名称（用于文本分块）
TIKTOKEN_MODEL_NAME=cl100k_base

# ========================================
# RAG配置
# ========================================
# 最大异步操作数
MAX_ASYNC=20
# 最大token数
MAX_TOKENS=32768
# 超时时间（秒），None表示无超时
TIMEOUT=None
# 对话历史轮数
HISTORY_TURNS=3
# 返回最相似结果的数量
TOP_K=50
# 余弦相似度阈值
COSINE_THRESHOLD=0.4

# ========================================
# 日志配置
# ========================================
# 日志级别 (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ========================================
# 安全配置
# ========================================
# API密钥认证
LIGHTRAG_API_KEY=
# 是否启用HTTPS
SSL=
# SSL证书文件路径
SSL_CERTFILE=
# SSL私钥文件路径
SSL_KEYFILE=

# ========================================
# 存储配置
# ========================================
# 键值存储类型
# 可选值：
# - JsonKVStorage: JSON文件存储（默认，轻量级，适合开发测试）
# - RedisKVStorage: Redis存储（高性能，适合生产环境）
# - MongoKVStorage: MongoDB存储（文档型数据库，适合大规模数据）
# - OracleKVStorage: Oracle数据库存储（企业级，高可用）
# - PGKVStorage: PostgreSQL存储（关系型数据库，功能丰富）
# - TiDBKVStorage: TiDB存储（分布式数据库，高扩展性）
KV_STORAGE=JsonKVStorage

# 向量存储类型
# 可选值：
# - NanoVectorDBStorage: Nano向量数据库（默认，轻量级，适合开发测试）
# - ChromaVectorDBStorage: Chroma向量数据库（功能丰富，支持元数据）
# - MilvusVectorDBStorage: Milvus向量数据库（高性能，适合大规模向量检索）
# - WeaviateVectorStorage: Weaviate向量数据库（图向量数据库，支持复杂查询）
# - PGVectorStorage: PostgreSQL pgvector扩展（关系型数据库集成）
# - TiDBVectorDBStorage: TiDB向量存储（分布式向量数据库）
VECTOR_STORAGE=NanoVectorDBStorage

# 图存储类型
# 可选值：
# - NetworkXStorage: NetworkX图存储（默认，Python原生，适合开发测试）
# - Neo4JStorage: Neo4j图数据库（专业图数据库，功能强大）
# - AGEStorage: PostgreSQL AGE扩展（图数据库扩展，性能优秀）
# - GremlinStorage: Gremlin图查询语言支持（标准图查询接口）
# - PGGraphStorage: PostgreSQL图存储（关系型数据库图扩展）
# - TiDBGraphStorage: TiDB图存储（分布式图数据库）
GRAPH_STORAGE=NetworkXStorage

# 文档状态存储类型
# 可选值：
# - JsonDocStatusStorage: JSON文件存储（默认，轻量级，适合开发测试）
# - RedisKVStorage: Redis存储（高性能，支持过期时间）
# - MongoKVStorage: MongoDB存储（文档型，支持复杂查询）
# - PGDocStatusStorage: PostgreSQL存储（关系型，支持事务）
# - TiDBKVStorage: TiDB存储（分布式，高可用）
DOC_STATUS_STORAGE=JsonDocStatusStorage

# ========================================
# 高级配置
# ========================================
# 节点嵌入算法
NODE_EMBEDDING_ALGORITHM=none
# 最大并行插入数
MAX_PARALLEL_INSERT=2
# 嵌入批处理大小
EMBEDDING_BATCH_NUM=32
# 嵌入函数最大异步数
EMBEDDING_FUNC_MAX_ASYNC=16
# LLM模型最大异步数
LLM_MODEL_MAX_ASYNC=16

# ========================================
# 文件监控配置（可选）
# ========================================
# 扫描间隔（秒）
SCAN_INTERVAL=300
# 最大文件大小（字节）
MAX_FILE_SIZE=104857600
# 是否启用实时文件监控
ENABLE_REALTIME_MONITOR=true

# 监控的文件夹路径
WATCH_PATH_1=./dataset/kotei
# WATCH_PATH_2=./uploads
# WATCH_PATH_3=./data

# 支持的文件扩展名
FILE_EXTENSIONS=.pdf,.docx,.doc,.txt,.md,.markdown,.pptx,.ppt,.png,.jpg,.jpeg,.bmp,.tiff,.gif,.log,.csv,.json,.xml,.html,.htm

# ========================================
# 实体提取配置（可选）
# ========================================
# 实体提取最大次数
ENTITY_EXTRACT_MAX_GLEANING=1
# 实体摘要最大token数
ENTITY_SUMMARY_TO_MAX_TOKENS=500

# ========================================
# 并行优化配置
# ========================================
# 是否启用并行实体提取
ENABLE_PARALLEL_ENTITY_EXTRACTION=true
# 并行实体提取最大并发数
PARALLEL_ENTITY_EXTRACTION_MAX_CONCURRENT=16
# 并行实体提取批处理大小
PARALLEL_ENTITY_EXTRACTION_BATCH_SIZE=10
# 是否启用智能批处理（根据内容长度动态调整）
ENABLE_SMART_BATCHING=true

# ========================================
# 多模态配置（可选）
# ========================================
# 多模态模型类型 (openai, llava, qwen-vl, none)
MULTIMODAL_MODEL_TYPE=none
# OpenAI API密钥（如果使用OpenAI Vision）
OPENAI_API_KEY=
# OpenAI模型名称
OPENAI_MODEL=gpt-4o-mini
# LLaVA模型路径
LLAVA_MODEL_PATH=liuhaotian/llava-v1.5-7b
# Qwen-VL模型路径
QWEN_VL_MODEL_PATH=Qwen/Qwen-VL-Chat
# 是否启用多模态理解
ENABLE_MULTIMODAL=false